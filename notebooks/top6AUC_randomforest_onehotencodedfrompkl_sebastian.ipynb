{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "mpl.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load training data from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_path = Path('..', 'data', 'input', 'dtypes.json')\n",
    "with open(dtypes_path) as f:\n",
    "    dtypes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = pd.read_pickle('../data/input/train.pkl')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract labels and raw feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train['HasDetections']\n",
    "\n",
    "feature_prefixes = list(train.columns)\n",
    "feature_prefixes.remove('MachineIdentifier')\n",
    "feature_prefixes.remove('HasDetections')\n",
    "\n",
    "# clean up\n",
    "del train\n",
    "\n",
    "# run gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load one-hot encoded training data from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_filtered_ohe = pd.read_pickle('../data/features/all_onehot_encoding_train.pkl')\n",
    "train_filtered_ohe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train classifier on top 6 features based on AUC of single features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set number of samples\n",
    "n_samples = int(np.round(1.0*len(train_filtered_ohe.index)))\n",
    "\n",
    "if n_samples < len(train_filtered_ohe.index):\n",
    "    # restrict to parts of the dataset (note: this access is VERY slow, likely caused by the way the sparse data is stored in the DataFrame)\n",
    "    train_filtered_ohe = train_filtered_ohe.head(n_samples)\n",
    "    labels = labels.head(n_samples)\n",
    "\n",
    "\n",
    "# top 6 features based on single feature AUC\n",
    "column_names = ['SmartScreen','AVProductStatesIdentifier','AVProductsInstalled','EngineVersion','Census_TotalPhysicalRAM','AppVersion']\n",
    "\n",
    "# get all columns belonging to a particular feature prefix\n",
    "cols_feature = [col for col in train_filtered_ohe.columns if col.startswith(tuple(column_names))]\n",
    " \n",
    "# convert sparse columns to dense\n",
    "data_as_dict = {}\n",
    "for col in cols_feature:\n",
    "    try:\n",
    "        data_as_dict[col] = train_filtered_ohe[[col]].sparse.to_dense()\n",
    "    except:\n",
    "        data_as_dict[col] = train_filtered_ohe[col].values\n",
    "\n",
    "# delete all features\n",
    "train_filtered_ohe.drop(columns=train_filtered_ohe.columns, inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "# convert back to data frame\n",
    "cols = list(data_as_dict.keys())\n",
    "for col in cols:\n",
    "    train_filtered_ohe[col] = data_as_dict[col]\n",
    "    del data_as_dict[col]\n",
    "    gc.collect()\n",
    "\n",
    "# clean up\n",
    "del data_as_dict, cols\n",
    "gc.collect()\n",
    "   \n",
    "print(train_filtered_ohe.info())\n",
    "print()\n",
    "    \n",
    "# create classifier\n",
    "clf = RandomForestClassifier(criterion='gini', max_depth=5, n_estimators=30, bootstrap=True)\n",
    "    \n",
    "# cross-validate classifier\n",
    "scores = cross_val_score(clf, train_filtered_ohe, labels, cv=7, scoring='roc_auc', verbose=2)\n",
    "    \n",
    "# report mean and stdev of AUC scores\n",
    "print('AUC (mean):', np.mean(scores))\n",
    "print('AUC (stdev):', np.std(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
