{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "mpl.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load training data from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_path = Path('..', 'data', 'input', 'dtypes.json')\n",
    "with open(dtypes_path) as f:\n",
    "    dtypes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.55 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8921483, 83)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_pickle('../data/input/train.pkl')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract labels and raw feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train['HasDetections']\n",
    "\n",
    "feature_prefixes = list(train.columns)\n",
    "feature_prefixes.remove('MachineIdentifier')\n",
    "feature_prefixes.remove('HasDetections')\n",
    "\n",
    "# clean up\n",
    "del train\n",
    "\n",
    "# run gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load one-hot encoded training data from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8921483 entries, 0 to 8921482\n",
      "Columns: 474 entries, ProductName_win8defender to Wdft_RegionIdentifier_nan\n",
      "dtypes: Sparse[uint8, 0](466), float16(4), float32(4)\n",
      "memory usage: 3.3 GB\n",
      "Wall time: 5.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_filtered_ohe = pd.read_pickle('../data/features/all_onehot_encoding_train.pkl')\n",
    "train_filtered_ohe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train classifier on top features based on importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8921483 entries, 0 to 8921482\n",
      "Data columns (total 16 columns):\n",
      "AVProductStatesIdentifier_7945.0     uint8\n",
      "AVProductStatesIdentifier_23657.0    uint8\n",
      "AVProductStatesIdentifier_46413.0    uint8\n",
      "AVProductStatesIdentifier_47238.0    uint8\n",
      "AVProductStatesIdentifier_53447.0    uint8\n",
      "AVProductStatesIdentifier_62773.0    uint8\n",
      "AVProductStatesIdentifier_nan        uint8\n",
      "AVProductsInstalled_1.0              uint8\n",
      "AVProductsInstalled_2.0              uint8\n",
      "AVProductsInstalled_3.0              uint8\n",
      "AVProductsInstalled_nan              uint8\n",
      "SmartScreen_ExistsNotSet             uint8\n",
      "SmartScreen_Off                      uint8\n",
      "SmartScreen_RequireAdmin             uint8\n",
      "SmartScreen_Warn                     uint8\n",
      "SmartScreen_nan                      uint8\n",
      "dtypes: uint8(16)\n",
      "memory usage: 204.2 MB\n",
      "None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  23.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   28.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  20.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  21.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  22.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  21.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  21.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  20.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (mean): 0.6398115809032695\n",
      "AUC (stdev): 0.00024397312388545797\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set number of samples\n",
    "n_samples = int(np.round(1.0*len(train_filtered_ohe.index)))\n",
    "\n",
    "if n_samples < len(train_filtered_ohe.index):\n",
    "    # restrict to parts of the dataset (note: this access is VERY slow, likely caused by the way the sparse data is stored in the DataFrame)\n",
    "    train_filtered_ohe = train_filtered_ohe.head(n_samples)\n",
    "    labels = labels.head(n_samples)\n",
    "\n",
    "\n",
    "# top features based on feature importance\n",
    "column_names = ['SmartScreen','AVProductStatesIdentifier','AVProductsInstalled']\n",
    "\n",
    "# get all columns belonging to a particular feature prefix\n",
    "cols_feature = [col for col in train_filtered_ohe.columns if col.startswith(tuple(column_names))]\n",
    " \n",
    "# convert sparse columns to dense\n",
    "data_as_dict = {}\n",
    "for col in cols_feature:\n",
    "    try:\n",
    "        data_as_dict[col] = train_filtered_ohe[[col]].sparse.to_dense()\n",
    "    except:\n",
    "        data_as_dict[col] = train_filtered_ohe[col].values\n",
    "\n",
    "# delete all features\n",
    "train_filtered_ohe.drop(columns=train_filtered_ohe.columns, inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "# convert back to data frame\n",
    "cols = list(data_as_dict.keys())\n",
    "for col in cols:\n",
    "    train_filtered_ohe[col] = data_as_dict[col]\n",
    "    del data_as_dict[col]\n",
    "    gc.collect()\n",
    "\n",
    "# clean up\n",
    "del data_as_dict, cols\n",
    "gc.collect()\n",
    "   \n",
    "print(train_filtered_ohe.info())\n",
    "print()\n",
    "    \n",
    "# create classifier\n",
    "clf = LogisticRegression(solver='liblinear', penalty='l2', C=1.0)\n",
    "    \n",
    "# cross-validate classifier\n",
    "scores = cross_val_score(clf, train_filtered_ohe, labels, cv=7, scoring='roc_auc', verbose=2)\n",
    "    \n",
    "# report mean and stdev of AUC scores\n",
    "print('AUC (mean):', np.mean(scores))\n",
    "print('AUC (stdev):', np.std(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
