{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "mpl.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load training data from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_path = Path('..', 'data', 'input', 'dtypes.json')\n",
    "with open(dtypes_path) as f:\n",
    "    dtypes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.88 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8921483, 83)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_pickle('../data/input/train.pkl')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract labels and raw feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train['HasDetections']\n",
    "\n",
    "feature_prefixes = list(train.columns)\n",
    "feature_prefixes.remove('MachineIdentifier')\n",
    "feature_prefixes.remove('HasDetections')\n",
    "\n",
    "# clean up\n",
    "del train\n",
    "\n",
    "# run gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load one-hot encoded training data from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8921483 entries, 0 to 8921482\n",
      "Columns: 474 entries, ProductName_win8defender to Wdft_RegionIdentifier_nan\n",
      "dtypes: Sparse[uint8, 0](466), float16(4), float32(4)\n",
      "memory usage: 3.3 GB\n",
      "Wall time: 5.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_filtered_ohe = pd.read_pickle('../data/features/all_onehot_encoding_train.pkl')\n",
    "train_filtered_ohe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train classifier on top 12 features based on AUC of single features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8921483 entries, 0 to 8921482\n",
      "Columns: 117 entries, EngineVersion_1.1.14600.4 to Census_OSBuildRevision_nan\n",
      "dtypes: float16(1), float32(1), uint8(115)\n",
      "memory usage: 1.1 GB\n",
      "None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 8.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  8.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 8.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 8.2min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 8.5min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 8.5min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 8.3min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 8.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 58.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (mean): 0.6734292630043223\n",
      "AUC (stdev): 0.0006695209088654452\n",
      "Wall time: 58min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set number of samples\n",
    "n_samples = int(np.round(1.0*len(train_filtered_ohe.index)))\n",
    "\n",
    "if n_samples < len(train_filtered_ohe.index):\n",
    "    # restrict to parts of the dataset (note: this access is VERY slow, likely caused by the way the sparse data is stored in the DataFrame)\n",
    "    train_filtered_ohe = train_filtered_ohe.head(n_samples)\n",
    "    labels = labels.head(n_samples)\n",
    "\n",
    "\n",
    "# top 12 features based on single feature AUC\n",
    "column_names = ['SmartScreen','AVProductStatesIdentifier','AVProductsInstalled','EngineVersion','Census_TotalPhysicalRAM','AppVersion','OsBuild','Census_OSBuildRevision','Census_OSVersion','OsBuildLab','Census_ProcessorCoreCount','Census_OEMNameIdentifier']\n",
    "\n",
    "# get all columns belonging to a particular feature prefix\n",
    "cols_feature = [col for col in train_filtered_ohe.columns if col.startswith(tuple(column_names))]\n",
    " \n",
    "# convert sparse columns to dense\n",
    "data_as_dict = {}\n",
    "for col in cols_feature:\n",
    "    try:\n",
    "        data_as_dict[col] = train_filtered_ohe[[col]].sparse.to_dense()\n",
    "    except:\n",
    "        data_as_dict[col] = train_filtered_ohe[col].values\n",
    "\n",
    "# delete all features\n",
    "train_filtered_ohe.drop(columns=train_filtered_ohe.columns, inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "# convert back to data frame\n",
    "cols = list(data_as_dict.keys())\n",
    "for col in cols:\n",
    "    train_filtered_ohe[col] = data_as_dict[col]\n",
    "    del data_as_dict[col]\n",
    "    gc.collect()\n",
    "\n",
    "# clean up\n",
    "del data_as_dict, cols\n",
    "gc.collect()\n",
    "   \n",
    "print(train_filtered_ohe.info())\n",
    "print()\n",
    "    \n",
    "# create classifier\n",
    "clf = RandomForestClassifier(criterion='gini', max_depth=8, n_estimators=30, bootstrap=True)\n",
    "    \n",
    "# cross-validate classifier\n",
    "scores = cross_val_score(clf, train_filtered_ohe, labels, cv=7, scoring='roc_auc', verbose=2)\n",
    "    \n",
    "# report mean and stdev of AUC scores\n",
    "print('AUC (mean):', np.mean(scores))\n",
    "print('AUC (stdev):', np.std(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
