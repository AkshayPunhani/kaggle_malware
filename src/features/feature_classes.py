import numpy as np
import pandas as pd
from pandas.api.types import CategoricalDtype
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from tqdm import tqdm

import sys
sys.path.append('..')
import gc
gc.enable()

from features import Feature


class AllLabelEncoding(Feature):
    """
    all features converted by label encoding
    """
    def create_features(self, train, test):
        # apply to only feature columns
        except_cols = ['MachineIdentifier', 'HasDetections']

        for col in tqdm(train.columns.tolist()):
            if col not in except_cols:
                # covert to str to regard nan as one category
                self.train[col] = train[col].astype('str')
                self.test[col] = test[col].astype('str')

                # create label encorder
                le = LabelEncoder().fit(
                    np.unique(
                        self.train[col].unique().tolist() +
                        self.test[col].unique().tolist()
                    ))

                # encording
                self.train[col] = le.transform(self.train[col])
                self.test[col] = le.transform(self.test[col])

                del le
                gc.collect()


class AllOnehotEncoding(Feature):
    """
    all features converted by one-hot encoding with sparse metrix
    """
    def create_features(self, train, test):
        # apply to only feature columns
        except_cols = ['MachineIdentifier', 'HasDetections']
        true_numeric_cols = [
            'Census_ProcessorCoreCount',
            'Census_PrimaryDiskTotalCapacity',
            'Census_SystemVolumeTotalCapacity',
            'Census_TotalPhysicalRAM',
            'Census_InternalPrimaryDiagonalDisplaySizeInInches',
            'Census_InternalPrimaryDisplayResolutionHorizontal',
            'Census_InternalPrimaryDisplayResolutionVertical',
            'Census_InternalBatteryNumberOfCharges'
        ]

        for col in tqdm(train.columns.tolist()):
            if col not in except_cols:
                if col not in true_numeric_cols:
                    # count data in each category
                    agg_tr = (train
                              .groupby([col])
                              .agg({'MachineIdentifier': 'count'})
                              .reset_index()
                              .rename({'MachineIdentifier': 'Train'}, axis=1))

                    agg_te = (test
                              .groupby([col])
                              .agg({'MachineIdentifier': 'count'})
                              .reset_index()
                              .rename({'MachineIdentifier': 'Test'}, axis=1))

                    # outer merge agg_tr and agg_te
                    agg = pd.merge(agg_tr, agg_te, on=col, how='outer').replace(np.nan, 0)

                    # drop category with less than 1000 observation in train
                    agg[col+'Copy'] = agg[col]
                    agg = agg[(agg['Train'] > 100000)].reset_index(drop=True)

                    # create new column with filtered categories
                    self.train[col] = (pd.merge(train[[col]],
                                                agg[[col, col + 'Copy']],
                                                on=col, how='left')[col + 'Copy']
                                       .astype(CategoricalDtype(categories=agg[col].tolist())))

                    self.test[col] = (pd.merge(test[[col]],
                                               agg[[col, col + 'Copy']],
                                               on=col, how='left')[col + 'Copy']
                                      .astype(CategoricalDtype(categories=agg[col].tolist())))

                    # add one-hot columns
                    self.train = pd.concat(
                        [self.train, pd.get_dummies(self.train[col], prefix=col, sparse=True, dummy_na=True)],axis=1)
                    self.test = pd.concat(
                        [self.test, pd.get_dummies(self.test[col], prefix=col, sparse=True, dummy_na=True)], axis=1)

                    # drop original columns
                    self.train.drop([col], axis=1, inplace=True)
                    self.test.drop([col], axis=1, inplace=True)

                    del agg, agg_tr, agg_te
                    gc.collect()
                else:
                    self.train[col] = train[col].fillna(np.nanmedian(train[col]))
                    self.test[col] = test[col].fillna(np.nanmedian(train[col]))
